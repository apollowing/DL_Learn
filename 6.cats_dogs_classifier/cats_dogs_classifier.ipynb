{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats and dogs classifier with hyperparameter tuning\n",
    "\n",
    "Created this project after I failed miserably at classifying open or closed windows\n",
    "\n",
    "I guess I do not have enough data? So I will try training the same setup with other kinds of images, \n",
    "\n",
    "like cats and dogs from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner\n",
    "!pip install tensorboard\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "# libraries for displaying images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from skimage import exposure\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters, BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform all installations\n",
    "!pip install tensorflow-gpu==2.5.0\n",
    "!pip install tensorflow-datasets\n",
    "!pip install tensorwatch\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# tfds makes a lot of progress bars and they take up a lot of screen space, so lets diable them\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "IMAGE_SIZE = (WIDTH, HEIGHT)\n",
    "NUM_CLASSES = 2\n",
    "CONTENT_DIR = r\"..\\contents\"\n",
    "TRAIN_DATA_DIR = os.path.join(CONTENT_DIR, r\"catdog_imgs\\train\\train\")\n",
    "TEST_DATA_DIR = os.path.join(CONTENT_DIR, r\"catdog_imgs\\test\\test\")\n",
    "LOG_DIR = r\".\\log\"\n",
    "LOG_HPARM = r\".\\log\\hparm\"\n",
    "TRAIN_SAMPLES = 9\n",
    "VAL_SAMPLES = 4\n",
    "BATCH_SIZE = 10\n",
    "EPOCH = 20\n",
    "CLASS_THRESHOLD = 0.5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "from datetime import datetime\n",
    "ts = datetime.now()\n",
    "ts = f\"{ts:%Y%m%d-%H%M%S}\"\n",
    "\n",
    "debug_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "load image data from directory and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(TRAIN_DATA_DIR)\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "  random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 TRAIN_DATA_DIR,x_col='filename',y_col='category',\n",
    "                                                 target_size=IMAGE_SIZE,\n",
    "                                                 class_mode='binary',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    TRAIN_DATA_DIR, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dogs-vs-cats/test/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=IMAGE_SIZE,\n",
    "                                                 class_mode='binary',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to show the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    for i in range(BATCH_SIZE):\n",
    "        print(f'Run #{i}')\n",
    "        img, label = train_generator.__next__()\n",
    "        # classval = np.argmax(label[0], axis = 0)    # convert one-hot encoding to index\n",
    "        # classkey = find_key(classval, iter_img.class_indices) # get class key from index value\n",
    "        plt.imshow(img[0])\n",
    "        plt.show()\n",
    "        # print(f'img shape {img.shape}')\n",
    "        # print(f'img label {classkey}\\n')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained modfel and add in fine tuning layers\n",
    "Now we define the model layers to freeze, discard to classification layers\n",
    "then finally add in the fine tuning layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_maker(hp):\n",
    "    # num_layers = hp.Int('num_layers', min_value=1, max_value=3)\n",
    "    toFlatten = hp.Choice('toFlatten', values=[True, False])\n",
    "    lr = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    # act = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "    custom_model = Sequential()\n",
    "    # load model\n",
    "    base_model = MobileNet(\n",
    "        include_top=False,\n",
    "        input_shape=(WIDTH, HEIGHT,3))\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "        \n",
    "    custom_model.add(base_model)\n",
    "    custom_model.add(GlobalAveragePooling2D())\n",
    "    if toFlatten:\n",
    "        custom_model.add(Flatten())\n",
    "\n",
    "    # for num in range(num_layers):\n",
    "    custom_model.add(Dense(hp.Int('units', min_value=16, max_value=128, step=16), activation = 'relu'))\n",
    "    custom_model.add(Dropout(hp.Float('dropout', min_value=0.3, max_value=0.6, step=0.1)))\n",
    "\n",
    "    custom_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    custom_model.compile(\n",
    "        loss =  'binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return custom_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "# from tensorflow.keras.optimizers import SGD,RMSprop,adam\n",
    "\n",
    "def model_maker_scratch():\n",
    "    from_scratch = Sequential()\n",
    "    from_scratch.add(Convolution2D(224, 3,3,input_shape=(WIDTH, HEIGHT, 3)))\n",
    "    from_scratch.add(Activation('relu'))\n",
    "    from_scratch.add(Convolution2D(1000, 3, 3))\n",
    "    from_scratch.add(Activation('relu'))\n",
    "    from_scratch.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    from_scratch.add(Dropout(0.5))\n",
    "    # from_scratch.add(Convolution2D(64, 3, 3))\n",
    "    from_scratch.add(Convolution2D(1000, 3, 3))\n",
    "    from_scratch.add(Activation('relu'))\n",
    "    from_scratch.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    from_scratch.add(Dropout(0.5))\n",
    "    # \n",
    "\n",
    "    from_scratch.add(Dense(256, activation='relu'))\n",
    "    from_scratch.add(Dropout(0.5))\n",
    "    from_scratch.add(Dense(1, activation='sigmoid'))\n",
    "    # from_scratch.add(Dense(1))\n",
    "    # from_scratch.add(Activation('sigmoid'))\n",
    "    return(from_scratch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch between models\n",
    "# model = model_maker_scratch()\n",
    "# model = model_maker_inceptionResNetV2()\n",
    "# model = model_maker()\n",
    "\n",
    "# lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# model.compile(\n",
    "#     loss = 'binary_crossentropy',\n",
    "#     optimizer=opt,\n",
    "#     metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "#Allow TensorBoard callbacks\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(f\"{LOG_DIR}\\{ts}\",\n",
    "                                                      histogram_freq=1,\n",
    "                                                      write_images=True)\n",
    "\n",
    "csv_logger = CSVLogger('dogscats-training-' + 'log.csv',\n",
    "                        append=True,\n",
    "                        separator=';')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.Hyperband(\n",
    "# \tmodel,\n",
    "# \tobjective=\"val_accuracy\",\n",
    "# \tmax_epochs=EPOCH,\n",
    "# \tfactor=3,\n",
    "# \tseed=42,\n",
    "# \tdirectory=LOG_DIR)\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "\tmodel_maker,\n",
    "\tobjective=\"val_accuracy\",\n",
    "\tmax_trials=5,\n",
    "\tseed=42,\n",
    "\tdirectory=LOG_HPARM)\n",
    "\n",
    "tuner.search(\n",
    "\ttrain_generator,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tepochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp = HyperParameters()\n",
    "# hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "# hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "\n",
    "# tuner = BayesianOptimization(\n",
    "#     hypermodel=model,  # Replace with your actual model\n",
    "#     objective='val_loss',  # The metric to optimize (minimize)\n",
    "#     max_trials=10,  # Number of trials (configurations) to test\n",
    "#     num_initial_points=3,  # Initial random samples\n",
    "#     alpha=0.0001,  # Noise level\n",
    "#     beta=2.6  # Exploration-exploitation balance\n",
    "# )\n",
    "\n",
    "# tuner.search(train_data=train_generator, epochs=10, validation_data=val_generator)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best number of units: {best_hps.get('units')}\")\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', min_delta=0.001, patience=10)\n",
    "\n",
    "best_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[tensorboard_callback,csv_logger,early_stopping],\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=math.ceil(float(VAL_SAMPLES)/BATCH_SIZE)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from gc import callbacks\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE),\n",
    "#     epochs=EPOCH,\n",
    "#     callbacks=[tensorboard_callback,csv_logger,early_stopping],\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=math.ceil(float(VAL_SAMPLES)/BATCH_SIZE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params={\n",
    "#         'batch_size':[64],  \n",
    "#         'nb_epoch':[10, 15, 20], \n",
    "#         'units':[64, 128, 256], \n",
    "#         'dropout': [0.2, 0.3, 0.4],\n",
    "#         } \n",
    "# gs=GridSearchCV(estimator=model, param_grid=params) \n",
    "# # now fit the dataset to the GridSearchCV object.  \n",
    "# gs = gs.fit(train_generator)\n",
    "\n",
    "\n",
    "# best_params=gs.best_params_ \n",
    "# accuracy=gs.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorBoard\n",
    "%tensorboard --logdir ./log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a 'history' object with training and validation loss\n",
    "# Example: history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)\n",
    "\n",
    "# Retrieve training and validation loss\n",
    "train_loss = best_model.history.history['loss'] \n",
    "val_loss = best_model.history.history['val_loss']\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss', marker='x')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = f'..\\contents\\models\\winclass_{ts}.h5'\n",
    "best_model.save(h5_path)\n",
    "tf.saved_model.save(best_model, \"tmp/model/1/\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Specify the file you want to copy\n",
    "source_file = h5_path\n",
    "destination_file = 'model.h5'\n",
    "\n",
    "# Copy the file\n",
    "shutil.copyfile(source_file, destination_file)\n",
    "\n",
    "print(f\"File copied successfully from {source_file} to {destination_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "result, cam_img = cam.read()\n",
    "if result:\n",
    "    \n",
    "    # cv2.imshow(\"Captured image\", cam_img)\n",
    "    # equ_img = cv2.equalizeHist(cam_img)\n",
    "    cv2.imwrite(TEST_DATA_DIR + r\"\\test_window.jpeg\", cam_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No image detected. Please try again.\") \n",
    "\n",
    "from skimage import exposure, transform\n",
    "from skimage.io import imread\n",
    "\n",
    "img_path = r'../contents/windows_imgs/test/test_window.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# img = imread(img_path)\n",
    "# img = exposure.equalize_hist(img)\n",
    "# new_shape = (224, 224)\n",
    "# img = transform.resize(img, new_shape, anti_aliasing=True)\n",
    "\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(val_generator.class_indices)\n",
    "\n",
    "# plt.figure(1,1)\n",
    "plt.title(f\"File Name: {img_path}, \\n Prediction: Window is  {'Close' if prediction < CLASS_THRESHOLD else 'Open'}\")\n",
    "plt.imshow(img)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, transform\n",
    "from skimage.io import imread\n",
    "\n",
    "img_path = r'../contents/windows_imgs/test/test_window.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# img = imread(img_path)\n",
    "# img = exposure.equalize_hist(img)\n",
    "# new_shape = (224, 224)\n",
    "# img = transform.resize(img, new_shape, anti_aliasing=True)\n",
    "\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(val_generator.class_indices)\n",
    "\n",
    "# plt.figure(1,1)\n",
    "plt.title(f\"File Name: {img_path}, \\n Prediction: Window is  {'Close' if prediction < CLASS_THRESHOLD else 'Open'}\")\n",
    "plt.imshow(img)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all images in test folder and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filelist = os.listdir(VAL_DATA_DIR + r\"/close/\")\n",
    "# filelist = os.listdir(TEST_DATA_DIR)\n",
    "jpegfiles = [file for file in filelist if file.endswith('.jpeg')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wanted to shrink the images down and display it inside a grid here.. work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## loop through file list and make a grid of images\n",
    "# cols = 3\n",
    "# rows = -(-jpegfiles.count // cols)\n",
    "# fig, axes = plt.subplot(3, rows, figsize(18,6))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# # Plot each image in the corresponding subplot\n",
    "# for i, image in enumerate(images):\n",
    "#     img = image.load_img(os.path.join(VAL_DATA_DIR  + r\"/close/\",file), target_size=(WIDTH,HEIGHT))\n",
    "#     # img = image.load_img(os.path.join(TEST_DATA_DIR,file), target_size=(WIDTH,HEIGHT))\n",
    "#     img_array = image.img_to_array(img)\n",
    "#     expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "#     preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "#     prediction = model.predict(preprocessed_img)\n",
    "#     print(prediction)\n",
    "#     print(val_generator.class_indices)\n",
    "\n",
    "#     ax = axes[i]\n",
    "#     ax.imshow(img)\n",
    "#     ax.title(f\"File Name: {file}, \\n Prediction: Window is  {'Close' if prediction < CLASS_THRESHOLD else 'Open'}\")\n",
    "\n",
    "#     ax.axis('off')  # Turn off axis labels\n",
    "\n",
    "# plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in jpegfiles:\n",
    "    img = image.load_img(os.path.join(VAL_DATA_DIR  + r\"/close/\",file), target_size=(WIDTH,HEIGHT))\n",
    "    # img = image.load_img(os.path.join(TEST_DATA_DIR,file), target_size=(WIDTH,HEIGHT))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "    print(prediction)\n",
    "    print(val_generator.class_indices)\n",
    "\n",
    "    plt.title(f\"File Name: {file}, \\n Prediction: Window is  {'Close' if prediction < CLASS_THRESHOLD else 'Open'}\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
